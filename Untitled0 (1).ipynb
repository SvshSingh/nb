{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install duckdb -q"
      ],
      "metadata": {
        "id": "DFtThbCjIq0c"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install paddleocr -q"
      ],
      "metadata": {
        "id": "w_4SMySLH8LW"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.15 -q"
      ],
      "metadata": {
        "id": "sembfep1JE3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "#import constants\n",
        "import os\n",
        "import requests\n",
        "import pandas as pd\n",
        "import multiprocessing\n",
        "import time\n",
        "from time import time as timer\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from functools import partial\n",
        "import requests\n",
        "import urllib\n",
        "from PIL import Image\n",
        "import argparse"
      ],
      "metadata": {
        "id": "RpNFz5bwvfSl"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "7R49evEgNYTp"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def common_mistake(unit):\n",
        "    if unit in constants.allowed_units:\n",
        "        return unit\n",
        "    if unit.replace('ter', 'tre') in constants.allowed_units:\n",
        "        return unit.replace('ter', 'tre')\n",
        "    if unit.replace('feet', 'foot') in constants.allowed_units:\n",
        "        return unit.replace('feet', 'foot')\n",
        "    return unit\n",
        "\n",
        "def parse_string(s):\n",
        "    s_stripped = \"\" if s==None or str(s)=='nan' else s.strip()\n",
        "    if s_stripped == \"\":\n",
        "        return None, None\n",
        "    pattern = re.compile(r'^-?\\d+(\\.\\d+)?\\s+[a-zA-Z\\s]+$')\n",
        "    if not pattern.match(s_stripped):\n",
        "        raise ValueError(\"Invalid format in {}\".format(s))\n",
        "    parts = s_stripped.split(maxsplit=1)\n",
        "    number = float(parts[0])\n",
        "    unit = common_mistake(parts[1])\n",
        "    if unit not in constants.allowed_units:\n",
        "        raise ValueError(\"Invalid unit [{}] found in {}. Allowed units: {}\".format(\n",
        "            unit, s, constants.allowed_units))\n",
        "    return number, unit\n",
        "\n",
        "\n",
        "def create_placeholder_image(image_save_path):\n",
        "    try:\n",
        "        placeholder_image = Image.new('RGB', (100, 100), color='black')\n",
        "        placeholder_image.save(image_save_path)\n",
        "    except Exception as e:\n",
        "        return\n",
        "\n",
        "def download_image(image_link, save_folder, retries=3, delay=3):\n",
        "    if not isinstance(image_link, str):\n",
        "        return\n",
        "\n",
        "    filename = Path(image_link).name\n",
        "    image_save_path = os.path.join(save_folder, filename)\n",
        "\n",
        "    if os.path.exists(image_save_path):\n",
        "        return\n",
        "\n",
        "    for _ in range(retries):\n",
        "        try:\n",
        "            urllib.request.urlretrieve(image_link, image_save_path)\n",
        "            return\n",
        "        except:\n",
        "            time.sleep(delay)\n",
        "\n",
        "    create_placeholder_image(image_save_path) #Create a black placeholder image for invalid links/images\n",
        "\n",
        "def download_images(image_links, download_folder, allow_multiprocessing=True):\n",
        "    if not os.path.exists(download_folder):\n",
        "        os.makedirs(download_folder)\n",
        "\n",
        "    if allow_multiprocessing:\n",
        "        download_image_partial = partial(\n",
        "            download_image, save_folder=download_folder, retries=3, delay=3)\n",
        "\n",
        "        with multiprocessing.Pool(64) as pool:\n",
        "            list(tqdm(pool.imap(download_image_partial, image_links), total=len(image_links)))\n",
        "            pool.close()\n",
        "            pool.join()\n",
        "    else:\n",
        "        for image_link in tqdm(image_links, total=len(image_links)):\n",
        "            download_image(image_link, save_folder=download_folder, retries=3, delay=3)\n"
      ],
      "metadata": {
        "id": "dwUbukvQw6-H"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "entity_unit_map = {\n",
        "    'width': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
        "    'depth': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
        "    'height': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
        "    'item_weight': {'gram',\n",
        "        'kilogram',\n",
        "        'microgram',\n",
        "        'milligram',\n",
        "        'ounce',\n",
        "        'pound',\n",
        "        'ton'},\n",
        "    'maximum_weight_recommendation': {'gram',\n",
        "        'kilogram',\n",
        "        'microgram',\n",
        "        'milligram',\n",
        "        'ounce',\n",
        "        'pound',\n",
        "        'ton'},\n",
        "    'voltage': {'kilovolt', 'millivolt', 'volt'},\n",
        "    'wattage': {'kilowatt', 'watt'},\n",
        "    'item_volume': {'centilitre',\n",
        "        'cubic foot',\n",
        "        'cubic inch',\n",
        "        'cup',\n",
        "        'decilitre',\n",
        "        'fluid ounce',\n",
        "        'gallon',\n",
        "        'imperial gallon',\n",
        "        'litre',\n",
        "        'microlitre',\n",
        "        'millilitre',\n",
        "        'pint',\n",
        "        'quart'}\n",
        "}\n",
        "\n",
        "allowed_units = {unit for entity in entity_unit_map for unit in entity_unit_map[entity]}"
      ],
      "metadata": {
        "id": "8cennCJCxbYX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('/content/train.csv')"
      ],
      "metadata": {
        "id": "vu-Wfu2VyAvb"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path='/content/train.csv'"
      ],
      "metadata": {
        "id": "RN_g71XnKDvL"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=duckdb.sql(f\"\"\"(SELECT *\n",
        "                        FROM '{train_path}'\n",
        "                        WHERE entity_name='width'\n",
        "                        ORDER BY random()\n",
        "                        LIMIT 10)\n",
        "                        UNION ALL\n",
        "                        (SELECT *\n",
        "                        FROM '{train_path}'\n",
        "                        WHERE entity_name='depth'\n",
        "                        ORDER BY random()\n",
        "                        LIMIT 10)\n",
        "                        UNION ALL\n",
        "                        (SELECT *\n",
        "                        FROM '{train_path}'\n",
        "                        WHERE entity_name='height'\n",
        "                        ORDER BY random()\n",
        "                        LIMIT 10)\n",
        "                        UNION ALL\n",
        "                        (SELECT *\n",
        "                        FROM '{train_path}'\n",
        "                        WHERE entity_name='item_weight'\n",
        "                        ORDER BY random()\n",
        "                        LIMIT 10)\n",
        "                        UNION ALL\n",
        "                        (SELECT *\n",
        "                        FROM '{train_path}'\n",
        "                        WHERE entity_name='maximum_weight_recommendation'\n",
        "                        ORDER BY random()\n",
        "                        LIMIT 10)\n",
        "                        UNION ALL\n",
        "                        (SELECT *\n",
        "                        FROM '{train_path}'\n",
        "                        WHERE entity_name='voltage'\n",
        "                        ORDER BY random()\n",
        "                        LIMIT 10)\n",
        "                        UNION ALL\n",
        "                        (SELECT *\n",
        "                        FROM '{train_path}'\n",
        "                        WHERE entity_name='wattage'\n",
        "                        ORDER BY random()\n",
        "                        LIMIT 10)\n",
        "                        UNION ALL\n",
        "                        (SELECT *\n",
        "                        FROM '{train_path}'\n",
        "                        WHERE entity_name='item_volume'\n",
        "                        ORDER BY random()\n",
        "                        LIMIT 10)\"\"\").to_df()"
      ],
      "metadata": {
        "id": "qqoSDHY7OJPT"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "download_images(df['image_link'], '/content/train_images')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tr0BRUrKOVUH",
        "outputId": "b567ea5f-28c2-4ea8-ac11-30c27e09a1b5"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 80/80 [00:01<00:00, 67.75it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('unique1.csv', index=False)"
      ],
      "metadata": {
        "id": "dUfmNwbNObPk"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageCaptionDataset(Dataset):\n",
        "    def __init__(self, csv_file, root_dir, transform=None):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.label_mapping = {name: idx for idx, name in enumerate(self.data['entity_name'].unique())}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.basename(self.data.iloc[idx, 0])\n",
        "        img_path = os.path.join(self.root_dir, img_name)\n",
        "        if not os.path.isfile(img_path):\n",
        "            print(f\"File {img_path} not found.\")\n",
        "            return None, None\n",
        "\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        label = self.data.iloc[idx, 2]\n",
        "        label = self.label_mapping[label]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, torch.tensor(label)"
      ],
      "metadata": {
        "id": "q1oB0XxHKbR8"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models import resnet50\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Data Augmentation for training set\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(20),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "class CustomRegressor(nn.Module):\n",
        "    def __init__(self, pretrained_model): # Changed _init_ to __init__\n",
        "        super(CustomRegressor, self).__init__() # Changed _init_ to __init__\n",
        "        self.backbone = pretrained_model\n",
        "        self.backbone.fc = nn.Identity()  # Remove the classification layer\n",
        "\n",
        "        # Fully connected layers for regression\n",
        "        self.fc1 = nn.Linear(2048, 512)\n",
        "        self.bn1 = nn.BatchNorm1d(512)\n",
        "        self.dropout1 = nn.Dropout(0.5)\n",
        "\n",
        "        self.fc2 = nn.Linear(512, 128)\n",
        "        self.bn2 = nn.BatchNorm1d(128)\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "\n",
        "        self.fc_numeric = nn.Linear(128, 1)  # For numeric output (e.g. item weight)\n",
        "        self.fc_unit = nn.Linear(128, 1)     # For unit prediction (optional)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.backbone(x)\n",
        "        x = F.relu(self.bn1(self.fc1(x)))\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        x = F.relu(self.bn2(self.fc2(x)))\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        numeric_output = self.fc_numeric(x)\n",
        "        unit_output = self.fc_unit(x)\n",
        "        return numeric_output, unit_output\n",
        "\n",
        "# Training function\n",
        "def train_model(model, train_loader, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    best_loss = float('inf')\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        total = 0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            numeric_pred, _ = outputs  # For now, we are focusing on numeric prediction\n",
        "            loss = criterion(numeric_pred.squeeze(1), labels.float())\n",
        "\n",
        "            # Backpropagation and optimization\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Gradient clipping\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            total += labels.size(0)\n",
        "\n",
        "        scheduler.step()\n",
        "        epoch_loss = running_loss / total\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")\n",
        "\n",
        "        # Save best model based on loss\n",
        "        if epoch_loss < best_loss:\n",
        "            best_loss = epoch_loss\n",
        "            torch.save(model.state_dict(), 'best_model.pth')\n"
      ],
      "metadata": {
        "id": "aDJGfO1tKKTY"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "    images = [item[0] for item in batch if item[0] is not None]\n",
        "    labels = [item[1] for item in batch if item[1] is not None]\n",
        "    if images:\n",
        "        images = torch.stack(images, dim=0)\n",
        "    else:\n",
        "        images = torch.empty(0)\n",
        "\n",
        "    if labels:\n",
        "        labels = torch.tensor(labels)\n",
        "    else:\n",
        "        labels = torch.empty(0)\n",
        "\n",
        "    return images, labels"
      ],
      "metadata": {
        "id": "rytBC841NyTS"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = ImageCaptionDataset('/content/unique1.csv', 'train_images', transform=train_transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=2, collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "oQIwABA9Lcky"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pretrained ResNet50 model\n",
        "pretrained_model = resnet50(pretrained=True)\n",
        "for param in pretrained_model.parameters():\n",
        "    param.requires_grad = False  # Freeze pretrained layers\n",
        "\n",
        "# Only fine-tune the last few layers\n",
        "for param in pretrained_model.layer4.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# Instantiate the custom regression model, loss function, and optimizer\n",
        "model = CustomRegressor(pretrained_model)\n",
        "criterion = nn.MSELoss()  # Mean Squared Error for regression task\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)  # L2 regularization\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NHBVfEaLp21",
        "outputId": "d0a503c4-b72c-4b5e-b0bb-8d1ed2307be0"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "train_model(model, train_loader, criterion, optimizer, scheduler, num_epochs=25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "us1dyw5qLmHb",
        "outputId": "9aca620d-8756-414a-c48e-74ab6c4224d2"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/25], Loss: 18.4542\n",
            "Epoch [2/25], Loss: 15.5891\n",
            "Epoch [3/25], Loss: 12.9108\n",
            "Epoch [4/25], Loss: 10.5949\n",
            "Epoch [5/25], Loss: 8.6016\n",
            "Epoch [6/25], Loss: 8.1794\n",
            "Epoch [7/25], Loss: 6.5162\n",
            "Epoch [8/25], Loss: 6.7084\n",
            "Epoch [9/25], Loss: 5.9417\n",
            "Epoch [10/25], Loss: 6.2570\n",
            "Epoch [11/25], Loss: 6.4298\n",
            "Epoch [12/25], Loss: 5.6403\n",
            "Epoch [13/25], Loss: 6.6272\n",
            "Epoch [14/25], Loss: 6.0464\n",
            "Epoch [15/25], Loss: 5.3896\n",
            "Epoch [16/25], Loss: 5.6620\n",
            "Epoch [17/25], Loss: 4.4905\n",
            "Epoch [18/25], Loss: 4.3901\n",
            "Epoch [19/25], Loss: 3.2424\n",
            "Epoch [20/25], Loss: 2.8637\n",
            "Epoch [21/25], Loss: 2.2112\n",
            "Epoch [22/25], Loss: 2.3658\n",
            "Epoch [23/25], Loss: 2.0478\n",
            "Epoch [24/25], Loss: 1.9424\n",
            "Epoch [25/25], Loss: 1.2122\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_values(model, data_loader, df):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    idx_offset = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, _ in data_loader: # Assuming your data loader returns a tuple of (images, labels)\n",
        "            if isinstance(images, tuple): # Check if images is a tuple\n",
        "                images = images[0] # If it is, extract the first element (assuming it's the image tensor)\n",
        "            outputs = model(images)\n",
        "            if isinstance(outputs, tuple): # Check if the model output is a tuple\n",
        "                outputs = outputs[0] # If it is, extract the first element (assuming it's the prediction tensor)\n",
        "            outputs = outputs.squeeze(1) # Now apply squeeze to the tensor\n",
        "            for i, output in enumerate(outputs):\n",
        "                predicted_value = output.item()\n",
        "                entity_name = df.iloc[idx_offset + i]['entity_name']\n",
        "                actual_value = df.iloc[idx_offset + i]['entity_value']\n",
        "\n",
        "                print(f\"Entity Name: {entity_name}, Actual Value: {actual_value}, Predicted Value: {predicted_value}\")\n",
        "                predictions.append((entity_name, actual_value, predicted_value))\n",
        "\n",
        "            idx_offset += len(images)\n",
        "    return predictions"
      ],
      "metadata": {
        "id": "Lt_nmFshRnMq"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = predict_values(model, train_loader, df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GnIo7gXrRost",
        "outputId": "43136e0c-dfad-4181-fb4e-67db74f2ca3e"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entity Name: width, Actual Value: 140.0 centimetre, Predicted Value: 4.452517986297607\n",
            "Entity Name: width, Actual Value: 6.3 inch, Predicted Value: 5.587839126586914\n",
            "Entity Name: width, Actual Value: 1.0 inch, Predicted Value: 0.47619763016700745\n",
            "Entity Name: width, Actual Value: 1.929 inch, Predicted Value: 7.478664875030518\n",
            "Entity Name: width, Actual Value: 140.0 centimetre, Predicted Value: 4.313096523284912\n",
            "Entity Name: width, Actual Value: 2.8 inch, Predicted Value: 0.905134379863739\n",
            "Entity Name: width, Actual Value: 23.0 centimetre, Predicted Value: 0.6642702221870422\n",
            "Entity Name: width, Actual Value: 63.0 inch, Predicted Value: 2.9115726947784424\n",
            "Entity Name: width, Actual Value: 3.3 inch, Predicted Value: 4.87693977355957\n",
            "Entity Name: width, Actual Value: 14.0 centimetre, Predicted Value: 0.3742329776287079\n",
            "Entity Name: depth, Actual Value: 66.0 centimetre, Predicted Value: 0.3043697476387024\n",
            "Entity Name: depth, Actual Value: 30.0 centimetre, Predicted Value: 3.4547390937805176\n",
            "Entity Name: depth, Actual Value: 22.5 centimetre, Predicted Value: 0.7481107115745544\n",
            "Entity Name: depth, Actual Value: 2.0 inch, Predicted Value: 3.5552804470062256\n",
            "Entity Name: depth, Actual Value: 800.0 millimetre, Predicted Value: 3.1678030490875244\n",
            "Entity Name: depth, Actual Value: 7.0 inch, Predicted Value: 3.4467551708221436\n",
            "Entity Name: depth, Actual Value: 28.5 centimetre, Predicted Value: 0.955058753490448\n",
            "Entity Name: depth, Actual Value: 1.3 metre, Predicted Value: 1.1329989433288574\n",
            "Entity Name: depth, Actual Value: 3.6 inch, Predicted Value: 4.23659086227417\n",
            "Entity Name: depth, Actual Value: 37.0 centimetre, Predicted Value: 2.522932767868042\n",
            "Entity Name: height, Actual Value: 182.4 centimetre, Predicted Value: 4.515495777130127\n",
            "Entity Name: height, Actual Value: 5.0 centimetre, Predicted Value: 5.110506057739258\n",
            "Entity Name: height, Actual Value: 11.5 centimetre, Predicted Value: 2.863783359527588\n",
            "Entity Name: height, Actual Value: 180.0 centimetre, Predicted Value: 3.1649160385131836\n",
            "Entity Name: height, Actual Value: 6.22 inch, Predicted Value: 0.1526111364364624\n",
            "Entity Name: height, Actual Value: 13.4 inch, Predicted Value: 0.9570414423942566\n",
            "Entity Name: height, Actual Value: 19.0 inch, Predicted Value: 2.130176544189453\n",
            "Entity Name: height, Actual Value: 9.45 inch, Predicted Value: 0.42366018891334534\n",
            "Entity Name: height, Actual Value: 4.4 inch, Predicted Value: 3.8877978324890137\n",
            "Entity Name: height, Actual Value: 3.5 centimetre, Predicted Value: 3.96669864654541\n",
            "Entity Name: item_weight, Actual Value: 10 milligram, Predicted Value: 1.5084623098373413\n",
            "Entity Name: item_weight, Actual Value: 10.0 gram, Predicted Value: 0.45143988728523254\n",
            "Entity Name: item_weight, Actual Value: 350.0 gram, Predicted Value: 2.692880392074585\n",
            "Entity Name: item_weight, Actual Value: 0.0 gram, Predicted Value: 5.810150623321533\n",
            "Entity Name: item_weight, Actual Value: 36.0 gram, Predicted Value: 4.357445240020752\n",
            "Entity Name: item_weight, Actual Value: 2.0 gram, Predicted Value: 0.4788738191127777\n",
            "Entity Name: item_weight, Actual Value: 500 gram, Predicted Value: 0.2340121567249298\n",
            "Entity Name: item_weight, Actual Value: 10.0 gram, Predicted Value: 3.036853551864624\n",
            "Entity Name: item_weight, Actual Value: 85 gram, Predicted Value: 4.0683465003967285\n",
            "Entity Name: item_weight, Actual Value: 300.0 gram, Predicted Value: 3.8306257724761963\n",
            "Entity Name: maximum_weight_recommendation, Actual Value: 1.0 ounce, Predicted Value: 2.688681125640869\n",
            "Entity Name: maximum_weight_recommendation, Actual Value: 5.0 kilogram, Predicted Value: 0.40994593501091003\n",
            "Entity Name: maximum_weight_recommendation, Actual Value: 450 pound, Predicted Value: 2.4048173427581787\n",
            "Entity Name: maximum_weight_recommendation, Actual Value: 0.6 kilogram, Predicted Value: 4.300961971282959\n",
            "Entity Name: maximum_weight_recommendation, Actual Value: 10 kilogram, Predicted Value: 0.2947295010089874\n",
            "Entity Name: maximum_weight_recommendation, Actual Value: 250 kilogram, Predicted Value: 2.3676412105560303\n",
            "Entity Name: maximum_weight_recommendation, Actual Value: 6.0 milligram, Predicted Value: 3.857455015182495\n",
            "Entity Name: maximum_weight_recommendation, Actual Value: 20 kilogram, Predicted Value: 1.0108963251113892\n",
            "Entity Name: maximum_weight_recommendation, Actual Value: 300 pound, Predicted Value: 5.8185715675354\n",
            "Entity Name: maximum_weight_recommendation, Actual Value: 300 kilogram, Predicted Value: 2.8415098190307617\n",
            "Entity Name: voltage, Actual Value: 5.0 volt, Predicted Value: 4.387400150299072\n",
            "Entity Name: voltage, Actual Value: 120.0 volt, Predicted Value: 4.135798454284668\n",
            "Entity Name: voltage, Actual Value: 220.0 volt, Predicted Value: 3.962003231048584\n",
            "Entity Name: voltage, Actual Value: [85.0, 265.0] volt, Predicted Value: 0.48473742604255676\n",
            "Entity Name: voltage, Actual Value: 24.0 volt, Predicted Value: 4.094564914703369\n",
            "Entity Name: voltage, Actual Value: 12.0 volt, Predicted Value: 3.5568675994873047\n",
            "Entity Name: voltage, Actual Value: 110.0 volt, Predicted Value: 6.5367865562438965\n",
            "Entity Name: voltage, Actual Value: [220.0, 240.0] volt, Predicted Value: 1.2468520402908325\n",
            "Entity Name: voltage, Actual Value: 12.0 volt, Predicted Value: 4.324692249298096\n",
            "Entity Name: voltage, Actual Value: 12.0 volt, Predicted Value: 0.6026278138160706\n",
            "Entity Name: wattage, Actual Value: 60.0 watt, Predicted Value: 3.967534303665161\n",
            "Entity Name: wattage, Actual Value: 2160.0 horsepower, Predicted Value: 0.8519319891929626\n",
            "Entity Name: wattage, Actual Value: 120.0 watt, Predicted Value: 3.6609392166137695\n",
            "Entity Name: wattage, Actual Value: 4.0 watt, Predicted Value: 7.6148247718811035\n",
            "Entity Name: wattage, Actual Value: 2.0 watt, Predicted Value: 4.58619499206543\n",
            "Entity Name: wattage, Actual Value: 60.0 watt, Predicted Value: 1.1971601247787476\n",
            "Entity Name: wattage, Actual Value: 40.0 watt, Predicted Value: 7.99590539932251\n",
            "Entity Name: wattage, Actual Value: 60.0 watt, Predicted Value: 2.7568225860595703\n",
            "Entity Name: wattage, Actual Value: 36.0 watt, Predicted Value: 7.817668437957764\n",
            "Entity Name: wattage, Actual Value: 250.0 watt, Predicted Value: 3.7757132053375244\n",
            "Entity Name: item_volume, Actual Value: 2.0 pint, Predicted Value: 4.637131690979004\n",
            "Entity Name: item_volume, Actual Value: 18.75 fluid ounce, Predicted Value: 4.0439982414245605\n",
            "Entity Name: item_volume, Actual Value: 44.5 cubic inch, Predicted Value: 0.6393193602561951\n",
            "Entity Name: item_volume, Actual Value: 1.67 fluid ounce, Predicted Value: 3.4054369926452637\n",
            "Entity Name: item_volume, Actual Value: 400.0 millilitre, Predicted Value: 4.8929314613342285\n",
            "Entity Name: item_volume, Actual Value: 2.0 fluid ounce, Predicted Value: 0.6993045210838318\n",
            "Entity Name: item_volume, Actual Value: 12.0 ounce, Predicted Value: 3.1003787517547607\n",
            "Entity Name: item_volume, Actual Value: 500.0 millilitre, Predicted Value: 0.4989077150821686\n",
            "Entity Name: item_volume, Actual Value: 250.0 millilitre, Predicted Value: 5.673463344573975\n",
            "Entity Name: item_volume, Actual Value: 50.0 millilitre, Predicted Value: 7.3435235023498535\n"
          ]
        }
      ]
    }
  ]
}